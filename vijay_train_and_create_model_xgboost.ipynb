{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa32ba4f",
   "metadata": {},
   "source": [
    "# Train a Model\n",
    "\n",
    "**TODO:**\n",
    "- Update code to use **SageMaker Python SDK V3**\n",
    "- Need to learn more about hyperparameters\n",
    "- Analyze XGBoost report\n",
    "\n",
    "## Model Training Overview\n",
    "\n",
    "**Note:** This notebook uses **SageMaker Python SDK V2**\n",
    "\n",
    "To train a machine learning model, we first need **clean and well-prepared data**.\n",
    "\n",
    "In my repository  ðŸ‘‰ **[AI_Learning_DataPrep_SageMaker](https://github.com/VijayBheemineni/AI_Learning_DataPrep_SageMaker)**,  \n",
    "I analyzed the `adult_data.csv` dataset, performed data cleaning and feature transformations, and split the data into three datasets:\n",
    "\n",
    "- **Training dataset**\n",
    "- **Validation dataset**\n",
    "- **Test dataset**\n",
    "\n",
    "All three processed CSV files are stored in **Amazon S3** and are used as inputs for model training and evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "## Choosing the Machine Learning Algorithm\n",
    "\n",
    "Once data preparation is complete, the next step is to select an appropriate **machine learning algorithm**.\n",
    "\n",
    "In this use case, the goal is to predict whether an individual's income is:\n",
    "- `>=50K` or\n",
    "- `<50K`\n",
    "\n",
    "Since the output has only **two possible outcomes**, this is a **binary classification problem**.  \n",
    "For this reason, I am using the **XGBoost algorithm**, which is well-suited for structured/tabular data and is commonly used for classification problems.\n",
    "\n",
    "---\n",
    "\n",
    "## What Happens During Model Training\n",
    "\n",
    "The objective of model training is to create a model that can make accurate predictions on **new, unseen data**.\n",
    "\n",
    "- The **training data** contains both input features and the target label (`income`)\n",
    "- Future data used for predictions **does not contain the target label**\n",
    "\n",
    "During training:\n",
    "- The algorithm learns patterns that map input features to the target\n",
    "- These learned patterns are stored as a **trained ML model**\n",
    "- This model can then be used to predict income categories for new data\n",
    "\n",
    "---\n",
    "\n",
    "## Hyperparameters and Model Tuning\n",
    "\n",
    "In addition to selecting an algorithm, we also configure **hyperparameters**.\n",
    "\n",
    "Hyperparameters:\n",
    "- Control how the training job runs\n",
    "- Influence model behavior and learning process\n",
    "- Have a significant impact on model performance and accuracy\n",
    "\n",
    "Selecting the right hyperparameter values is an important part of training an effective model.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74746a08",
   "metadata": {},
   "source": [
    "## Task 1: Setup the Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7b9f93",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Install matplotlib, bokeh, seaborn and restart kernel\n",
    "%pip install matplotlib # Low level plotting library to create static plots\n",
    "%pip uninstall bokeh -y # Python Visualization Library for creating interactive charts\n",
    "%pip install bokeh==2.4.2\n",
    "%pip install seaborn # High level statistical visualization library built on Matplotlib\n",
    "%reset -f\n",
    "\n",
    "# Import packages\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import sagemaker\n",
    "from sagemaker.debugger import Rule, rule_configs\n",
    "from sagemaker import image_uris\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "boto3_session = boto3.Session()\n",
    "sagemaker_client = boto3_session.client('sagemaker')\n",
    "\n",
    "# Reload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc63eea",
   "metadata": {},
   "source": [
    "## Task 2: Check if S3 bucket exists and accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f0211b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Check if S3 bucket exists\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "def check_s3_bucket(bucket_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Check if the S3 bucket exists and is accessible.\n",
    "\n",
    "    Args:\n",
    "        bucket_name (str): Name of the S3 bucket.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if bucket exists and accessible, False otherwise.\n",
    "    \"\"\"\n",
    "    s3 = boto3.client('s3')\n",
    "    try:\n",
    "        s3.head_bucket(Bucket=bucket_name)\n",
    "        return True\n",
    "    except ClientError:\n",
    "        return False\n",
    "\n",
    "\n",
    "def get_user_input(prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Prompt user for input and ensure it's not empty.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): Prompt text to display.\n",
    "\n",
    "    Returns:\n",
    "        str: User input.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        value = input(prompt).strip()\n",
    "        if value:\n",
    "            return value\n",
    "        print(\"Input cannot be empty. Please try again.\")\n",
    "\n",
    "\n",
    "# -------------------------\n",
    "# Interactive inputs\n",
    "# -------------------------\n",
    "bucket_name = get_user_input(\"Enter the S3 bucket name: \")\n",
    "prefix = get_user_input(\n",
    "    \"Enter prefix/folder path which contains data (e.g., 'scripts/data'): \"\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# Check bucket existence\n",
    "# -------------------------\n",
    "if not check_s3_bucket(bucket_name):\n",
    "    raise ValueError(\n",
    "        f\"S3 Bucket '{bucket_name}' does not exist or you don't have access!\"\n",
    "    )\n",
    "\n",
    "print(f\"S3 Bucket '{bucket_name}' exists âœ…\")\n",
    "print(f\"Prefix/folder to use: '{prefix}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3c4d12",
   "metadata": {},
   "source": [
    "## Task 3: Configure S3 datasets path and Training Input Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2e5b8c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Configure S3 'train', 'validation' dataset paths.\n",
    "train_path = f\"s3://{bucket_name}/{prefix}/train/adult_data_processed_train.csv\"\n",
    "validation_path = f\"s3://{bucket_name}/{prefix}/validation/adult_data_processed_validation.csv\"\n",
    "test_path = f\"s3://{bucket_name}/{prefix}/test/adult_data_processed_test.csv\"\n",
    "\n",
    "# Set up the TrainingInput objects. Setting S3 as datasource.\n",
    "train_input = TrainingInput(train_path, content_type='text/csv')\n",
    "validation_input = TrainingInput(validation_path, content_type='text/csv')\n",
    "test_input = TrainingInput(test_path, content_type='text/csv')\n",
    "\n",
    "print(f'Training path: {train_path}')\n",
    "print(f'Validation path: {validation_path}')\n",
    "print(f'Test path: {test_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4e9c3a",
   "metadata": {},
   "source": [
    "## Task 4: Retrieve 'xgboost' container URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8f5a1b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Generate a unique run name\n",
    "# -----------------------------\n",
    "create_date = strftime(\"%Y%m%d-%H%M%S\")\n",
    "run_name = f\"vijay-xgboost-income-classification-{create_date}\"\n",
    "\n",
    "# -----------------------------\n",
    "# Retrieve XGBoost container URI\n",
    "# https://docs.aws.amazon.com/sagemaker/latest/dg-ecr-paths/ecr-us-west-2.html#xgboost-us-west-2\n",
    "# -----------------------------\n",
    "FRAMEWORK_NAME = \"xgboost\"\n",
    "FRAMEWORK_VERSION = \"1.7-1\"\n",
    "\n",
    "container_uri = image_uris.retrieve(\n",
    "    framework=FRAMEWORK_NAME,\n",
    "    region=region,\n",
    "    version=FRAMEWORK_VERSION\n",
    ")\n",
    "\n",
    "print(f\"XGBoost container URI: {container_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5d8e2f",
   "metadata": {},
   "source": [
    "## Task 5: Create \"Estimator\" object\n",
    "\n",
    "- https://sagemaker.readthedocs.io/en/v2.20.0/api/\n",
    "- https://sagemaker.readthedocs.io/en/v2.20.0/amazon_sagemaker_debugger.html#pre-defined-debugger-hook-configuration-for-built-in-rules\n",
    "- https://docs.aws.amazon.com/sagemaker/latest/dg/debugger-built-in-rules.html\n",
    "\n",
    "### What is an Estimator\n",
    "\n",
    "An Estimator is a configuration object that tells SageMaker:\n",
    "\n",
    "- which algorithm to use\n",
    "- where the data is\n",
    "- what infrastructure to use\n",
    "- how to run the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c9d3e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Configuration\n",
    "# =========================\n",
    "INSTANCE_TYPE = \"ml.m5.xlarge\"\n",
    "INSTANCE_COUNT = 1\n",
    "FRAMEWORK_NAME = \"xgboost\"\n",
    "\n",
    "# S3 Location where Model Artifact will be stored.\n",
    "output_path = f\"s3://{bucket_name}/{prefix}/output\"\n",
    "\n",
    "print(f\"SageMaker SDK Version: {sagemaker.__version__}\")\n",
    "print(f\"Training output path: {output_path}\")\n",
    "print(f\"Instance type: {INSTANCE_TYPE}\")\n",
    "print(f\"Instance count: {INSTANCE_COUNT}\")\n",
    "\n",
    "# =========================\n",
    "# XGBoost Estimator\n",
    "# =========================\n",
    "xgboost_estimator = sagemaker.estimator.Estimator(\n",
    "    image_uri=container_uri,\n",
    "    role=role,\n",
    "    instance_count=INSTANCE_COUNT,\n",
    "    instance_type=INSTANCE_TYPE,\n",
    "    output_path=output_path,\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    rules=[Rule.sagemaker(rule_configs.create_xgboost_report())],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8e4f1a",
   "metadata": {},
   "source": [
    "## Task 6: Setting HyperParameters\n",
    "\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html\n",
    "\n",
    "### What are HyperParameters?\n",
    "\n",
    "Think of hyperparameters as the \"settings\" or \"knobs\" you adjust before training your model. They're like the settings on a camera before you take a photo - you adjust them based on what you're trying to capture.\n",
    "\n",
    "Unlike the patterns the model learns from data (which are called \"parameters\"), hyperparameters are values **you set beforehand** to control how the learning process works.\n",
    "\n",
    "For example, in XGBoost:\n",
    "- **max_depth**: How deep should each decision tree grow? (like deciding how many questions to ask before making a decision)\n",
    "- **learning_rate**: How quickly should the model learn? (too fast and it might miss details, too slow and it takes forever)\n",
    "- **num_round**: How many trees should we build? (more trees can mean better accuracy, but also more computation time)\n",
    "\n",
    "Finding the right hyperparameter values is part art, part science - it often requires experimentation to see what works best for your specific problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f2e3b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Need to learn more about these parameters\n",
    "XGBOOST_HYPERPARAMETERS = {\n",
    "    \"max_depth\": 5,\n",
    "    \"eta\": 0.2,\n",
    "    \"gamma\": 4,\n",
    "    \"min_child_weight\": 6,\n",
    "    \"subsample\": 0.7,\n",
    "    \"verbosity\": 0,\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": 800,\n",
    "}\n",
    "xgboost_estimator.set_hyperparameters(**XGBOOST_HYPERPARAMETERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3f5d2a",
   "metadata": {},
   "source": [
    "## Task 7: Training the Model\n",
    "\n",
    "The `fit()` method starts the training job. We will call the method with training and validation datasets.\n",
    "\n",
    "https://sagemaker.readthedocs.io/en/v2.40.0/api/training/estimators.html#sagemaker.estimator.EstimatorBase.fit\n",
    "\n",
    "### Check Training Job Status\n",
    "\n",
    "AWS Console --> SageMaker AI --> Model training & customization --> Training & tuning jobs --> check for job which starts with \"vijay-xgboost-income-classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4a6b3c",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "run_timestamp = strftime(\"%Y%m%d-%H%M%S\")\n",
    "training_job_name = f\"vijay-xgboost-income-classifier-{run_timestamp}\"\n",
    "\n",
    "training_data = {\n",
    "    \"train\": train_input,\n",
    "    \"validation\": validation_input,\n",
    "}\n",
    "\n",
    "xgboost_estimator.fit(\n",
    "    inputs=training_data,\n",
    "    job_name=training_job_name,\n",
    "    wait=True,\n",
    "    logs=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "## Task 8: Artifacts\n",
    "\n",
    "After training completes, SageMaker generates several important outputs called \"artifacts\". Think of these as the deliverables from your training job.\n",
    "\n",
    "The main artifacts include:\n",
    "\n",
    "1. **Model Artifact**: This is the trained model itself - the actual file that contains all the learned patterns from your data. It's saved as a compressed file (tar.gz) in S3 and can be deployed to make predictions.\n",
    "\n",
    "2. **XGBoost Report**: This is an automated analysis report generated by SageMaker Debugger. It provides insights into how well your model trained, including metrics, potential issues, and recommendations for improvement.\n",
    "\n",
    "These artifacts are stored in the S3 output path we configured earlier, making them easy to access and use for deployment or further analysis.\n",
    "\n",
    "**TODO:** Analyze XGBoost report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4d5e6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "output_path = xgboost_estimator.output_path.rstrip(\"/\")\n",
    "job_name = xgboost_estimator.latest_training_job.job_name\n",
    "\n",
    "xgboost_model_output = f\"{output_path}/{job_name}/output\"\n",
    "xgboost_report = f\"{output_path}/{job_name}/rule-output/CreateXgboostReport\"\n",
    "\n",
    "print(f\"Model artifacts stored at: {xgboost_model_output}\")\n",
    "print(f\"XGBoost training report stored at: {xgboost_report}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e6d7c8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary\n",
    "\n",
    "This repository focuses on the model training stage of my AWS AI learning journey using Amazon SageMaker. It builds on previously prepared and processed datasets and demonstrates how to train a binary classification model using the XGBoost algorithm.\n",
    "\n",
    "The notebook covers:\n",
    "\n",
    "- Configuring a SageMaker training job\n",
    "- Selecting and tuning model hyperparameters\n",
    "- Training and validating the model using structured data stored in Amazon S3\n",
    "- Monitoring training performance and reviewing generated model artifacts and reports"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
